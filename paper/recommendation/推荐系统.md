[TOC]

# 推荐系统 Recommender Systems An Introduction：

# 协同过滤推荐

主要思想：利用已有用户群过去的行为或意见预测当前用户最可能喜欢那些东西或对哪些东西感兴趣。输出形式:1.对物品的评分2.top-N列表。

## 基于用户的最近邻推荐

度量用户的相似度：Pearson相关系数。

$$sim(a,b) = \frac{\sum_{p\in P} (r_{a,p} - \bar{r}_a)(r_{b,p}-\bar{r}_b)}{\sqrt{\sum_{p\in P}(r_{a,p} -\bar{r}_a)} \sqrt{\sum_{p\in P}(r_{b,p} -\bar{r}_b)}}$$

$\bar{r}_a$表示用户a的平均分。



改进的余弦相似度，Spearman秩相关系数或均方差都可以作为用户间的相似度度量。余弦比Pearson好。

## 基于物品的最近邻推荐

余弦相似度。$sim(\vec{a},\vec{b}) = \frac{\vec{a}\cdot\vec{b}}{|\vec{a}|*|\vec{b}|}$



传统的基于用户的协同过滤问题：**算法不能很好的适应大规模用户和物品数据**

显式评分与隐式评分

协同过滤的冷启动和数据稀疏问题：1.如何向还没有给任何物品评分的新用户推荐；2.如何处理从未被评分过或购买过的物品。通用方法是使用额外信息。



协同推荐一般分成：**基于记忆的**和**基于模型的**。



## 矩阵因子分解

奇异值分解（SVF），在信息检索方面，**潜在语义分析(LSA)**也归于潜**在语义索引**(LSI)。

SVD原理：将给定矩阵M分解成3个矩阵的乘积。UV分别称为左右奇异向量，$\Sigma$对角线上的值称为奇异值。V对应用户，U对应物品。

$M = U\Sigma V^T$



# 基于内容的推荐

CF不需要知道物品的任何信息。内容：物品特征的描述。

基于内容推荐的原理：评估用户还没看到的物品与当前用户过去喜欢的物品的相似程度。

相似度度量：

$\frac{2\times |keywords(b_i) \cap keywords(j_j)|}{|keywords(b_i) |+| keywords(j_j)|}$

文档使用TF-IDF向量表示,文档j，关键词i：

$TF(i,j) = \frac{freq(i,j)}{maxOthers(i,j)}$

$IDF(i) = \log\frac{N}{n(i)}$

$TF-IDF(i,j) = TF(i,j) * IDF(i)$

TF是文档j中当前词i的频率比上文档j中最大的单词频率，IDF，N是所有文档数量，n(i)是出现单词i的文档数量。

将相似度度量看成分类问题，使用机器学习算法：决策树 贝叶斯



# 基于知识的推荐

基于知识的推荐：不需要评分数据就能推荐，所以不存在冷启动问题。推荐结果要么是以用户需求与产品之间的相似度的形式，要么根据明确的推荐规则。关于推荐系统是什么，传统解释一般强度信息过滤。而只是推荐的交互性很强，这个基本性质也是其作为**会话式系统**的原因。交互性稍微改变使得推荐系统不在仅仅看成一种过滤系统，而是更为广义的“以一种个性化方法引导用户的大量潜在后选中找到感兴趣或有用的物品，或者产生这些物品作为出书结果”的系统。Burke2000将基于知识的推荐系统定义为依赖协同过滤和基于内容方法没有用到的信息源的推荐系统。

基于知识推荐系统的两种基本类型是：基于约束推荐，基于实例推荐

基于约束类似于用户明确需求下的查询

基于实例类似给用户一个物品，用户会选价格低点的，然后再选像素更少点的。。。浏览



# 推荐系统的解释

**透明性**：解释能让推荐更加透明，目的是提供给用户信息，时期能够理解用来生成特定

**正确性**

**可信性**

**说服力**

**有效性**

**效率**

**满意度**

**关联度**

**可理解性**

**角度**



# 评估推荐系统

内在有效性，外在有效性。

有效性，可靠性，灵敏度

数据稀疏度量（R评分，I项目， U用户）：

$sparsity = 1-\frac{|R|}{|I|\cdot|U|}$

评估指标：

MAE, precision, recall, F1 , hitrate, ranksocre, ILS列表内相似度



# 推荐系统原理与实践：

# 推荐系统概述

“协同过滤”市值协同处理大量用户的评分来预测遗失的评分。其很少包含附加的数据类型信息。而基于内容的推荐则考虑了物品的描述信息，来对用户兴趣建模。基于知识的推荐系统则包含了相关领域知识。

推荐系统的目标：

1. 预测模型，将评分矩阵进行补全，已有的为有训练数据，缺失的为需要预测的。
2. 排名模型，不需要具体的评分，只需要top-n物品

推荐系统在操作和技术上的目标：

1. 相关性 用户与物品相关，但并不充分。
2. 新颖性 如果用户没见过这个物品，则推荐有效
3. 意外性 推荐的物品出乎意料
4. 提高推荐的多样性 当所有的推荐物品都非常相似，用户很容易反感。

推荐系统的基本模型：

模型数据：i）用户-物品之间的相互关系，比如评分过购买 ii）用户和物品的属性信息，例如文本画像或相关关键词。用到前一种数据的方法叫做**协同过滤**方法，用到后者的叫做**基于内容的推荐方法**。基于内容推荐多数情况也会使用评分矩阵。基于知识的推荐，是基于用户提出的明确说明，不在根据以往的评分信息或购买数据进行推荐，而是利用外部知识库和约束为用户推荐。

**协同过滤模型**

协同过滤模型是通过对大量用户给出的评分协同处理给出推荐。基本思想是由已知评分估计位置评分。

1. 基于记忆的方法(基于金鳞的协同过滤算法)，近邻的定义为两种：
   1. 基于用户的协同过滤：确定谁和目标用户A相似，用户A的位置评分可以由A的同类群体的加权平均值算出来。
   2. 基于物品的协同过滤：针对用户A与指定物品B做出评分预测，线确定与B类似的物品集合S，用户A对物品集S中的物品的评分用来预测用户A是否会喜欢物品B。
2. 基于模型的方法：使用机器学习或数据挖掘技术。模型可包括决策树，基于规则的模型，贝叶斯方法和潜在因子模型。**此处加多篇引用**。

潜在因子模型很早提出，最近研究表明，一些基于记忆和基于模型的方法结合体能提供非常准确结果。

**显式评分矩阵**，如果矩阵的值不是评分而是用户诸如购买物品的一个行为创建的，则称为**隐式反馈矩阵**。

协同过滤与缺失值分析密切相关(**此处加多篇引用**)。

**基于内容的推荐系统**

物品的描述性属性被用来做推荐。

缺点：

1. 由于其是基于关键词或内容推荐，很多情况都是一种显而易见的推荐。如一个用户从来都没有消费国具有一组关键词的物品，那这种物品是不可能被推荐的 
2.  尽管推荐内容的方法在提供新物品推荐时是有限的，但不能有效的为新用户做出推荐。因为训练模型需要用到她的历史评分。

所以基于内容与协同过滤各有侧重。基于内容与基于知识通常被认为是紧密相关的，有时候会之一其明确的界限。

**基于知识的推荐系统**

评分不是用来做推荐的。该系统是基于客户需求和物品描述之间的相似性做推荐，或利用指定用户需求的约束做推荐。



| 方法     | 概念上目标                                               |                            |
| -------- | -------------------------------------------------------- | -------------------------- |
| 协同     | 利用我的同组群体评分和行为给出推荐                       | 用户评分+社区评分          |
| 基于内容 | 基于我过去的评分和行为根据我所喜欢的内容（属性）做出推荐 | 用户评分+物品属性          |
| 基于知识 | 基于我对某些内容(属性)的精确要求给出推荐                 | 用户要求+物品属性+领域知识 |

1. 基于约束的推荐系统
2. 基于案例的推荐系统

如何实现基于知识的推荐系统的互动性？

1. 会话式系统
2. 基于搜索的系统
3. 基于导航的推荐



# 2 基于近邻的协同过滤

评分矩阵类型：连续评分，间隔评分，顺序评分，二元评分，一元评分。

**长尾分布**。

## 基于用户的近邻模型

利用每位用户$u$的评分计算每位用户的平均评分$\mu_u$

$$\mu_u = \frac{\sum_{k\in I_u} r_{uk}}{|I_u|}$$

使用Pearson相关系数定义相似度

$Sim(u,v) = Pearson(u,v) = \frac{\sum_{k\in I_u \cap I_v} (r_{uk}- \mu_{u}) \cdot (r_{vk}-\mu_{v}) }{\sqrt{\sum_{k \in I_u \cap i_v} (r_{uk}- \mu_{u})^2} \cdot \sqrt{\sum_{k \in I_u \cap i_v} (r_{vk}- \mu_{v})^2} }$

但不同的用户其评分尺度不同。所以进行均值中心化：

$s_{uj} = r_{rj} - \mu_u \forall u \in \{1...m\}$

整体的预测：

$\hat{r}_{u,j} = \mu_u + \frac{\sum_{v\in P_u(j)} Sim(u,v) \cdot s_{vj}}{|\sum_{v\in P_u(j)} Sim(u,v) |} = \mu_u + \frac{\sum_{v\in P_u(j)} Sim(u,v) \cdot (r_{vj}-\mu_{v})}{|\sum_{v\in P_u(j)} Sim(u,v) |}$

**普通理解**：

对目标用户与候选用户两两计算Pearson相似度，再对每用户的评分进行均值化处理，目标用户u对物品j的预测值等于用户u的评分均值加上前k个Pearson用户的Pearson值(权重)乘以均值化后的用户对物品j的评分。



相似度函数变形：RawCosine，DiscountedSim等。

降低长尾效应对Pearson影响，添加物品j权重$w_j$（idf概念）:

$w_j = \log(\frac{m}{m_j}) \forall j \in \{1...n\}$

$ Pearson(u,v) = \frac{\sum_{k\in I_u \cap I_v} w_k \cdot (r_{uk}- \mu_{u}) \cdot (r_{vk}-\mu_{v}) }{\sqrt{\sum_{k \in I_u \cap i_v} (r_{uk}- \mu_{u})^2} \cdot \sqrt{\sum_{k \in I_u \cap i_v} (r_{vk}- \mu_{v})^2} }$



## 基于物品的近邻模型

物品i与j的相似度计算：

$AdjustedConsine(i,j) = \frac{\sum_{u\in U_i \cap U_j} s_{u_i} \cdot s_{u_j}}{\sqrt{\sum_{u\in U_i \cap U_j} s_{ui}^2 } \cdot \sqrt{\sum_{u\in U_i \cap U_j} s_{uj}^2 }}$

用户u对物品t的预测评分：

$\hat{r}_{ut} =  \frac{\sum_{j \in Q_t(u)} AdjustedCosine(j,t) r_{uj}}{\sum_{j \in Q_t(u)}|AdjustedCosine(j,t)|}$





基于近邻的方法优势是简单和直观，但里现阶段在大规模数据上变得无法实现，基于用户的方法，其离线阶段要求至少$O(m^2)$， 可扩展性不够实用。

## 降维与近邻方法

使用PCA或SVD对评价矩阵降维。如对用户的协同过滤降维，将mxn的矩阵降维成mxd，d远小于n。

## 近邻方法的回归模型视角

基于用户的模型将预测评分表达为同一列ovs的评分的线性组合。而基于物品的模型表达为同一行中评分的线性组合。基于近邻的模型是线性回归模型的启发式变形，其中系统被启发式的设定为相关物品/用户的相似性，不相关则系数为0。**论文引用**

**基于用户的最近邻回归**

$\text{Minimize}\ J_u = \sum_{j\in I_u}(r_{uj} - \hat{r}_{uj})^2$

同时添加了用户偏置项，物品偏置项，调节因子，正则化。

基于物品的与之类似



## 基于紧邻方法的图模型

**用户-物品图**

不使用Pearson相关系数，而是使用结构化测度定义近邻，其是无向二分图。

这样可以使用**随机游走**定义近邻，更进一步的可以使用**Katz**(加权走)定义近邻

**物品-物品图**

用评分矩阵中的并集数量作为边的值，然后对结点的出度进行归一化。



# 3 基于模型的协同过滤

传统的分类或回归问题恰好是矩阵补全(或协同过滤)的特例。通常最精确的协同过滤方法都是基于模型的，尤其是潜在因子模型。潜在因子模型，对于解决协同过滤问题非常有效，但并不认为是解决数据分类的问题有效模型。

**决策和回归树**

对数据降维，然后对n个物品创建n个决策树。预测用户i对物品j的评分，mxd的矩阵第i行被用作测试数据，第j个决策'/回归树作为模型。

**基于规则的协同过滤**

面向物品的模型与面向用户的模型。关联规则的方法在基于Web的个性化推荐系统中得到了广泛应用，还是可使用序列模式挖掘模型，进一步扩展到包含时间信息的数据上。

**朴素贝叶斯协同过滤**

例子很简单，可见书籍64页。

## 潜在因子模型

潜在因子模型在推荐系统中被认为是一种最先进的方法。矩阵银子分解给出了一种优雅的同时利用行列相关性来估计整个数据矩阵的方法。其复杂度时期称为协同过滤中最先进的方法。

几何解释：

思想：在于找到一个隐向量集合，使得基于这些隐向量定义的从超平面到数据点(表示用户的单个评分值)的均方距离尽可能地小。因此，我们必须使用部分确定的数据集去恢复数据近似存在的低维度超平面。不过，如果数据没有任何关联性和冗余，那潜在因子模型是无法工作的。

低秩解释：

 其作用是因为因子分解(factorization)作用。评分矩阵可以表示为：

$R\approx UV^T$

U是空间的基，V是列空间的基。U的行记为用户因子，其包含与用户i对评分矩阵中的k各概念的亲和度相对应的k个值。每一列称为隐向量。

各矩阵分解方法之间的关键差异出现在对U和V的约束如潜在向量的正交性或非负性和目标函数性质。

**无约束矩阵分解**

对因子矩阵UV我有约束，许多文献将无约束矩阵分解当作奇异值分解SVD，严格说 是错误的。在SVD中，UV的列表示都是正交的。

UV的优化方式：梯度下降和交替最小二乘

交替最小二乘：

1. 固定U不变，将问题转化为n个最小二乘问题，每个物品是独立的，所以可以并行化。
2. 固定V不变，同样转化成m个最小二乘问题，
3. 两步迭代，直到收敛。

加权版本的ALS特别适合隐式反馈。但它效率不如大规模已知评分情况下的随机梯度下降。

改进：添加用户和物品偏差，减少过拟合。

![1561366302556](C:\Users\chenshuai\AppData\Roaming\Typora\typora-user-images\1561366302556.png)



引入隐式的反馈

非对称因子模型，$R\approx [FY]V^T$, 这种方法更有效，基本思想是：如果两个用户已经评价了e类似的物品，就会有类似的用户因子，而无需考虑具体的评分值。并且其参数量更小于U的mxk 因为n<<m。另一个有点是不需要用户参数化。

## 奇异值分解

如果矩阵R完全已知且未使用正则化，在SVD和非约束矩阵分解情况下，J的最优值是相同的。目标函数$J=\frac{1}{2}||R-UV^T||^2$

R不完全已知情况下，首先对矩阵进行均值化处理并用0填充?（即对预测值使用均值进行填充），然后使用SVD对这些位置进行更新，直到收敛。这方法不能保证收敛到全局最优，当大部分值未知时更明显，初始偏差对结果影响更大。

## 非负矩阵分解

NMF的优点在于可解释性。

**隐式反馈中的数值表示为置信度，而显示反馈中的数值表示偏好。**



## 总结

协同过滤于分类问题密切相关。

机器学习与推荐算法密切相关：关联规则，朴素贝叶斯，SVM，决策/回归树。甚至神经网络如RBM都应用

潜在因子方法是协同过滤最先进的方法。基本目标函数和约束的变体被应用于不同形式的矩阵分解。

关于如何选择底层优化问题的解决方法工作已经开展很多。



## 4 基于内容的推荐系统

基于内容的推荐系统尝试为用户匹配那些与其喜欢的物品相似的物品，这种相似度不一定基于用户之间的评分相关性，而是基于用户喜欢对象的属性。相比CF，更关注目标用户自己的评分，以及用户喜欢物品的属性。其它用户在基于内容的系统中角色不太重要，基于内容的方法利用不同的数据源来给出推荐。

依赖的两个数据来源： 

1. 根据以内容为中心的属性对各种物品的描述，如物品文本描述。
2. 用户画像。根据用户对各种物品的反馈而生成。有显式和隐式反馈。 前者对应评分，后者对应用户动作。

在基于内容的推荐算法中，其它用户的评分同上没有任何作用。，如冷启动问题，只要有足够的用户自己兴趣信息可用，就可以使用基于内容的推荐方法。减轻了冷启动问题。缺点可能是对用户的推荐缺乏多样性。基于内容的推荐可以使用结构或非结构化属性信息。

基于内容的系统的主要组件：(离线)预处理，(离线)学习部分，在线预测部分。

1. 预处理和特征提取：
2. 基于内容的用户画像学习：
3. 过滤和推荐

自动学习各特征的重要性称为**特征加权**。

收集用户的偏好，用户对物品的喜欢或不喜欢最终被转换为一元，二元，基于区间的或实数评分。获取评分的过程也可以被看作是提取要用户学习的类标签或因变量的过程。

提取关键词的数量应控制在50-300之间。

基尼指数更容易理解，熵度量具有更坚实的信息论的数学基础。

CHI2统计量可以通过将单词和类的共同出现处理为列联表来计算。其可以度量列链表中不同歌唱的观测值和期望值之间的归一化偏差。值越大表示特定此和物品有更高的相关程度，可以取CHI2前K个特征。



基于内容的优点：

1. 基于内容的系统仅对新用户具有冷启动问题，而协同系统对新用户和新物品都有冷启动问题。
2. 在物品的特征上有一定的解释性，但协同通常没有办法给出这样的解释
3. 基于内容的方法可以与县城的文本分类一起使用。

缺点：

1. 基于内容的系统倾向于找到与用户迄今为止所看的类似物品，称为 **过度特化**，即缺乏新颖性 多样性。
2. 无法解决新用户的冷启动问题。



# 5 基于知识的推荐系统

基于知识的推荐系统的适应情况：

1. 用户想要明确描述其需求，因此系统中必须有交互组件。协同过滤和基于内容的系统都不允许这种类型的用户反馈。
2. 由于物品的类型和选项导致的物品域的复杂性，某些特定类型的物品评分可能很呐获得。
3. 评分对时间敏感。



| 模型     | 关注点        | 物品属性 | 交互性 | 概念目标                                                 | 输入                           |
| -------- | ------------- | -------- | ------ | -------------------------------------------------------- | ------------------------------ |
| 协同过滤 | 其它用户/物品 | 不关心   | 无     | 基于协同的方法利用用户本人或同伴的评分和活动给出推荐结果 | 用户评分+社区评分              |
| 基于内容 | 自身          | 关心     | 无     | 基于用户过去对内容(属性)的评分和活动，给出推荐结果       | 用户评分+物品属性              |
| 基于知识 | 自身          | 关心     | 有     | 基于用户明确的内容(属性)需求说明，给出推荐结果           | 用户需求说明+物品属性+领域知识 |



根据用户的交互方法和辅助用户交互的相关知识库，基于知识的推荐系统可以分成：

1. 基于约束的推荐系统，以物品的属性为起点
2. 基于案例的推荐系统，以实例为起点

交互的三种实现：会话系统，搜索系统，导航系统



相似性度量，传统的是按照重要程度排序。

考虑d个属性来描述产品的应用，我们想确定在d个属性的邻域的子集S上定义的两个部分属性向量之间的相似度值。X为已知，T表示目标。相似度计算：

$f(\bar{T},\bar{X}) = \frac{\sum_{i \in S} w_i \cdot \text{Sim}(t_i, x_i)}{\sum_{i \in S} w_i}$

而X,Y的第i个属性相似度计算：

$\text{Sim}(t_i, x_i) = 1 - \frac{|t_i - x_i|}{\text{max}_i - \text{min}_i}$

在对称度量情况下，相似度完全由两个属性之间的差异定义，但在非对称属性情况下，可以额外添加一个非对称奖励。这取决于目标属性值更大还是更小。当目标值更大时候好，计算如下：

$\text{Sim}(t_i, x_i) = 1 - \frac{|t_i-x_i|}{\max_i - \min_i} + \underbrace{\alpha_i \cdot I(x_i>t_i) \cdot \frac{|t_i-x_i|}{\max_i -\min_i}}_{\text{非对称奖励}}$

$\alpha_i \ge 0$是用户定义的参数，$I(x_i>t_i)$是指示函数，如果$x_i > t_i$，则取值为1，否则为0。这样，当属性值大于目标值时候，奖励才生效。



**在相似度计算中合并多样性**

一种方法是在排名$b \cdot k$中，选择$k$个进行推荐，效果并不好。称为 有界随机选择策略。

另一种是有界贪婪选择策略。先选取排名$b \cdot k$，然后递增地从这协众创建一个多样的包含k中实例的集合。



基于知识的推荐系统往往是为了给更昂贵和偶尔购买的物品设计的，其是高度量身定制的。



# 6 基于集成的呼和推荐模型

协同过滤：使用一个社区(commuity)中所有用户的评分来做推荐。

基于内容：使用单一用户评分和以属性为中心的物品描述来做推荐。

基于知识：需要根据用户明确的需求来做推荐，而不需要任何历史评分。



# 7 推荐系统评估

虽然强化学习已经再分类和回归建模有关的文献资料中被广泛地研究过，但是其再推荐领域的相关研究是相当有限的。

1. 精确度

   评分的准确性：MSE或RMSE

   评估排名的准确性：ROC

2. 覆盖率

3. 置信度和信任度

4. 新颖度

5. 惊喜度

6. 多样性

7. 健壮性 

8. 可扩展性



相关性评估排名

1）Spearman等级相关系数。

2）肯德尔等级相关系数



通用效用评估排名(综合考虑排名和评分数值)：

1. $R-score(u) = \sum_{j \in I_u} F(u,j) \ F(u,j) = \frac{\max\{r_{uj} - C_u, 0\}}{2^{v_j-1}/\alpha}$

2. NDCG(归一化折扣累积收益)

   $DCG=\frac{1}{m}\sum_{u=1}^{m}\sum_{j\in I_u} \frac{g_{uj}}{\log_2(v_j+1)}, g_{uj} = 2^{\text{rel}_{uj}-1}$

   $g_{uj}$表示用户$u$从物品$j$中获得的效益，$\text{rel}_{uj}$表示用户$u$和物品$j$的真是相关性，通过评分值或点击率的启发函数来计算的。$v_j$表示物品$j$在测试集$I_u$中的排名。

   $\text{NDCG} = \frac{\text{DCG}}{\text{IDCG}}$

3. ARHR(MRR，平均命中率)

   $\text{ARHR}(u)=\sum_{j\in I_u}\frac{r_{uj}}{v_j}$

4. ROC曲线

   如果推荐列表过，算法将错过相关物品(假阴性)。如果推荐列表过大，会导致很多用户压根不会使用的虚假推荐(假阳性)。对于任意给定的列表大小值$t$，推荐列表集合表示$\mathcal{S}(t)$, 注意$|\mathcal{S}(t)| = t$。则精度计算如下：

   $\text{Precision}(t) = 100 \cdot \frac{|\mathcal{S} \cap \mathcal{G}|}{|\mathcal{S}(t)|}$

   召回率的计算如下：

   $\text{Recall}(t) = 100 \cdot \frac{|\mathcal{S}(t)\cap \mathcal{G}|}{|\mathcal{G}|}$

   准确率和召回率之间的一个自然平衡因子：

   $F_1(t) = \frac{2\cdot \text{Precision}(t) \cdot \text{Recall}(t)}{ \text{Precision}(t) +\text{Recall}(t)}$

   

   # 8 上下文敏感的推荐系统

   传统的推荐问题可以看作时学习从用户-物品对到评分值之间的映射函数。对应的函数$f_R$表示：
   
   $f_R:U\times I \rightarrow \text{rating}$
   
   这是一个二维矩阵，可以对维度进行扩充，表示任何类型的上下文。这个准则促进了多维的推荐方法。看作是从$w$维的值到评分的一个映射：
   
   $g_R:D_1 \times D_2 \times ... \times D_w \rightarrow \text{ratting}$
   
   
   
   分解机可以看作是多项式回归在抵抗稀疏问题的泛化。
   
   上下文感知的推荐有三种主要方法：预过滤方法中，是在应用协同过滤算法之前，把$w$维的数据立方体过滤成一个二维的评分矩阵，从而把问题变成一个二维的协同过滤稳妥。在后过滤的方法中，在协同过滤的第一阶段，是忽略上下文的。随后使用一个能调节上下文相关重要性的预测模型来调整结果。最后用一个最近提出的方法将上下文直接嵌入模型中，把它念成一个$w$维的预测问题。
   
   
   
   

# 9 时间与位置敏感的推荐系统

**时间协同过滤**

1. 基于新近的模型，在协同过滤的模型中对最近的评分给与更大的重要性
   1. 基于衰减的
   2. 基于窗口的
2. 周期的基于上下文的模型
   1. 预过滤和后过滤
   2. 时间上下文的直接合并
3. 把时间作为独立变量模型
   1. 将评分建模为与时间相关的函数，代表为**time-SVD++**。



**离散时间建模**

1. 马尔可夫模型

2. 序列模式挖掘

   可以将**关联规则**模式推广到这里。



**位置感知推荐系统**

信息不多



# 10 网络中的结构化推荐

在网络(如社交和信息网络)中的。搜索与推荐是不同的概念。结构化推荐的每一种不同的类型都可能在不同的场景中具有不同的应用集。这些不同变体的关键例子如下：

1. **按权威和上下文推荐结点**：在这种情况下，结点的质量由链入其的连接判断，结点的个性化相关性由其上下文判断。传统的在这种引擎中的搜索概念不区分各种类型的用户，因此不能对特定用户推荐。
2. **通过示例推荐结点**：推荐与其它示例结点相似的结点，这就是结点的集合分类问题。这应用到信息网络中也是有用的。
3. **通过影响力和内容推荐结点**：在许多以网络为中心的应用中，用户可能会传播有关各种类型产品的知识，称为*病毒式营销*。在 *主题敏感* 影响分析中，会搜索最可能传播特定主题用户。
4. **推荐链接**： 为了社交利益而增加网络的连接性。

## 排序算法

**PageRank**

目的是提高搜索质量。PageRank算法以递归的方式推广了基于引用排序的概念。

在网络中，结点对应网页，边对应超链接。基本思想是，高声誉的文档更有可能被其它有良好信誉的网页所引用(或链接)。同样，在推特中，高质量用户会被其它良好声誉用户关注。

PageRank算法根据随机访问的长期访问频率对网页的声誉进行建模。这个长期频率也被称为 *稳态概率*， 并且改模型也被称为 *随机游走模型*。

随机游走模型的两个修改：1. 将链接从死端结点添加到所有结点，包括自身的自循环。但还是能遇到 *死端分量*问题，导致无法在整个网络继续游走。2. *传递*或*重启步*。在每个转换中，随机游走可以跳转到具有概率$\alpha$(一般取0.1)的任意一个网页，或者以(1-$\alpha$)的概率跟随页面上的链接之一。

结点$i$的稳态概率$\pi(i)$是传递到它的概率与一种一个入链结点的概率会直接转换到它的概率之和：

$\pi(i) = \alpha / n + (1-\alpha) \cdot \sum_{j \in \text{In}(i)} \pi(j) \cdot p_{ji}$

方程组可以用矩阵形式重写：

$\bar{\pi} = \alpha \bar{e}/n + (1-\alpha)\textbf{P}^T\bar{\pi} , \sum_{i=1}^{n}\pi(i)=1$

> $\bar{\pi} = (\pi(1)...\pi(n))^T$， 并且$\bar{e}$是一个n维全为1的向量。可以很容易理解，这个公式上是一个公式的矩阵化实现

可以通过幂迭代法进行求解。

**个性化PageRank**

PageRank是根据链接结构找到流行结点的很好机制，但寻找特定用户的兴趣相匹配的物品基本无用。而个性化PageRank可以，其又称为主题敏感PageRank。

首先确定主题及主题的样本示例集合。

然后令$\bar{e}_p$为每个页面的一元n维个性化(列)向量。如果该页面在样本集中，则$\bar{e}_p$中的项值取值为1，否则为0。$\bar{e}_p$中的非零项的数目使用$n_p$表示。PageRank的公式改写如下：

$\bar{\pi} = \alpha \bar{e}_p/n_p + (1-\alpha)\textbf{P}^T\bar{\pi} $

$\alpha$较大时候，对主题更加敏感，较小时候对网络的结构更加敏感。



个性化PageRank方法可以被视为一种方法，其基于结点对于重启结点的结构相似度和结点对于其它结点的绝对连接度，想结点提供相似度分数。但$\alpha$的控制有效。取大值，失去了该方法计算在重启结点适度距离上的结点相似度的敏感度，只有重启结点才能接收到大部分的概率。



**SimRank**

用户计算结点之间的结构相似度，是对称相似度的。

$\text{SimRank}(i,j) = \frac{C}{|\text{In}(i)|\cdot |\text{In}(j)|}\sum_{p\in \text{In}(i)} \sum_{q\in\text{In}(j)} \text{SimRank}(p,q)$

C是(0,1)中的一个常数，可以理解为衰减率。边界条件，当i==j时，SimRank(i,j)设置为1。当i或j没有入链结点时候，SimRank(i,j)设置为0。

SimRank仍然有很大的不适应性，需要了解。



## 使用集合分类的推荐

**迭代分类算法(ICA)**

$n_t$记为未标记的测试结点。

在每次迭代中，$n_t/T$(测试)结点标签通过该方法“确定”。

**使用随机游走的标签传播**

假设图是通过 *标签* 联通的。 

**社交网络中协同过滤的适用性**



## 推荐好友：链路预测

**基于近邻的方法**

公共邻居度量：

$\text{CommonNeighbors}(i,j) = |S_i \cap Sj|$

但这种度量不考虑节点之间的公共邻居的相对数量。如果A和B分别是垃圾邮件制造者和与大量其他演员相关的非常受欢迎的公众人物。AB有很多共同邻居。

**Jaccard度量**

$\text{JaccardPredict}(i,j) = \frac{|S_i \cup S_j|}{|S_i \cup s_j|}$

Jaccard度量不能很好适应中间邻居的度。

**Adamic-Adar度量**

$\text{Adamic-Adar}(i,j) = \sum_{k \in S_i \cap S_j} \frac{1}{\log |S_k|}$



**Katz度量**

基于近邻的度量在一对结点间形成链接的可能性提供了健壮的估计，但当一对结点之间的公共邻居很少时候，这些度量不是很有效。

$\text{Katz}(i,j) = \sum_{t=1}^{\infin} \beta^t\cdot n_{ij}^{(t)}$

> $n_{ij}^{(t)} 是结点i和结点j之间长度t的行走的数量。$$\beta<1$ 



基于随机游走的度量：作为分类问题的链路预测，链路预测的矩阵分解，链路预测与协同过滤。



后几章内容未列