[TOC]

# 推荐系统 Recommender Systems An Introduction：

# 协同过滤推荐

主要思想：利用已有用户群过去的行为或意见预测当前用户最可能喜欢那些东西或对哪些东西感兴趣。输出形式:1.对物品的评分2.top-N列表。

## 基于用户的最近邻推荐

度量用户的相似度：Pearson相关系数。

$$sim(a,b) = \frac{\sum_{p\in P} (r_{a,p} - \bar{r}_a)(r_{b,p}-\bar{r}_b)}{\sqrt{\sum_{p\in P}(r_{a,p} -\bar{r}_a)} \sqrt{\sum_{p\in P}(r_{b,p} -\bar{r}_b)}}$$

$\bar{r}_a$表示用户a的平均分。



改进的余弦相似度，Spearman秩相关系数或均方差都可以作为用户间的相似度度量。余弦比Pearson好。

## 基于物品的最近邻推荐

余弦相似度。$sim(\vec{a},\vec{b}) = \frac{\vec{a}\cdot\vec{b}}{|\vec{a}|*|\vec{b}|}$



传统的基于用户的协同过滤问题：**算法不能很好的适应大规模用户和物品数据**

显式评分与隐式评分

协同过滤的冷启动和数据稀疏问题：1.如何向还没有给任何物品评分的新用户推荐；2.如何处理从未被评分过或购买过的物品。通用方法是使用额外信息。



协同推荐一般分成：**基于记忆的**和**基于模型的**。



## 矩阵因子分解

奇异值分解（SVF），在信息检索方面，**潜在语义分析(LSA)**也归于潜**在语义索引**(LSI)。

SVD原理：将给定矩阵M分解成3个矩阵的乘积。UV分别称为左右奇异向量，$\Sigma$对角线上的值称为奇异值。V对应用户，U对应物品。

$M = U\Sigma V^T$



# 基于内容的推荐

CF不需要知道物品的任何信息。内容：物品特征的描述。

基于内容推荐的原理：评估用户还没看到的物品与当前用户过去喜欢的物品的相似程度。

相似度度量：

$\frac{2\times |keywords(b_i) \cap keywords(j_j)|}{|keywords(b_i) |+| keywords(j_j)|}$

文档使用TF-IDF向量表示,文档j，关键词i：

$TF(i,j) = \frac{freq(i,j)}{maxOthers(i,j)}$

$IDF(i) = \log\frac{N}{n(i)}$

$TF-IDF(i,j) = TF(i,j) * IDF(i)$

TF是文档j中当前词i的频率比上文档j中最大的单词频率，IDF，N是所有文档数量，n(i)是出现单词i的文档数量。

将相似度度量看成分类问题，使用机器学习算法：决策树 贝叶斯



# 基于知识的推荐

基于知识的推荐：不需要评分数据就能推荐，所以不存在冷启动问题。推荐结果要么是以用户需求与产品之间的相似度的形式，要么根据明确的推荐规则。关于推荐系统是什么，传统解释一般强度信息过滤。而只是推荐的交互性很强，这个基本性质也是其作为**会话式系统**的原因。交互性稍微改变使得推荐系统不在仅仅看成一种过滤系统，而是更为广义的“以一种个性化方法引导用户的大量潜在后选中找到感兴趣或有用的物品，或者产生这些物品作为出书结果”的系统。Burke2000将基于知识的推荐系统定义为依赖协同过滤和基于内容方法没有用到的信息源的推荐系统。

基于知识推荐系统的两种基本类型是：基于约束推荐，基于实例推荐

基于约束类似于用户明确需求下的查询

基于实例类似给用户一个物品，用户会选价格低点的，然后再选像素更少点的。。。浏览



# 推荐系统的解释

**透明性**：解释能让推荐更加透明，目的是提供给用户信息，时期能够理解用来生成特定

**正确性**

**可信性**

**说服力**

**有效性**

**效率**

**满意度**

**关联度**

**可理解性**

**角度**



# 评估推荐系统

内在有效性，外在有效性。

有效性，可靠性，灵敏度

数据稀疏度量（R评分，I项目， U用户）：

$sparsity = 1-\frac{|R|}{|I|\cdot|U|}$

评估指标：

MAE, precision, recall, F1 , hitrate, ranksocre, ILS列表内相似度



# 推荐系统原理与实践：

# 推荐系统概述

“协同过滤”市值协同处理大量用户的评分来预测遗失的评分。其很少包含附加的数据类型信息。而基于内容的推荐则考虑了物品的描述信息，来对用户兴趣建模。基于知识的推荐系统则包含了相关领域知识。

推荐系统的目标：

1. 预测模型，将评分矩阵进行补全，已有的为有训练数据，缺失的为需要预测的。
2. 排名模型，不需要具体的评分，只需要top-n物品

推荐系统在操作和技术上的目标：

1. 相关性 用户与物品相关，但并不充分。
2. 新颖性 如果用户没见过这个物品，则推荐有效
3. 意外性 推荐的物品出乎意料
4. 提高推荐的多样性 当所有的推荐物品都非常相似，用户很容易反感。

推荐系统的基本模型：

模型数据：i）用户-物品之间的相互关系，比如评分过购买 ii）用户和物品的属性信息，例如文本画像或相关关键词。用到前一种数据的方法叫做**协同过滤**方法，用到后者的叫做**基于内容的推荐方法**。基于内容推荐多数情况也会使用评分矩阵。基于知识的推荐，是基于用户提出的明确说明，不在根据以往的评分信息或购买数据进行推荐，而是利用外部知识库和约束为用户推荐。

**协同过滤模型**

协同过滤模型是通过对大量用户给出的评分协同处理给出推荐。基本思想是由已知评分估计位置评分。

1. 基于记忆的方法(基于金鳞的协同过滤算法)，近邻的定义为两种：
   1. 基于用户的协同过滤：确定谁和目标用户A相似，用户A的位置评分可以由A的同类群体的加权平均值算出来。
   2. 基于物品的协同过滤：针对用户A与指定物品B做出评分预测，线确定与B类似的物品集合S，用户A对物品集S中的物品的评分用来预测用户A是否会喜欢物品B。
2. 基于模型的方法：使用机器学习或数据挖掘技术。模型可包括决策树，基于规则的模型，贝叶斯方法和潜在因子模型。**此处加多篇引用**。

潜在因子模型很早提出，最近研究表明，一些基于记忆和基于模型的方法结合体能提供非常准确结果。

**显式评分矩阵**，如果矩阵的值不是评分而是用户诸如购买物品的一个行为创建的，则称为**隐式反馈矩阵**。

协同过滤与缺失值分析密切相关(**此处加多篇引用**)。

**基于内容的推荐系统**

物品的描述性属性被用来做推荐。

缺点：

1. 由于其是基于关键词或内容推荐，很多情况都是一种显而易见的推荐。如一个用户从来都没有消费国具有一组关键词的物品，那这种物品是不可能被推荐的 
2.  尽管推荐内容的方法在提供新物品推荐时是有限的，但不能有效的为新用户做出推荐。因为训练模型需要用到她的历史评分。

所以基于内容与协同过滤各有侧重。基于内容与基于知识通常被认为是紧密相关的，有时候会之一其明确的界限。

**基于知识的推荐系统**

评分不是用来做推荐的。该系统是基于客户需求和物品描述之间的相似性做推荐，或利用指定用户需求的约束做推荐。



| 方法     | 概念上目标                                               |                            |
| -------- | -------------------------------------------------------- | -------------------------- |
| 协同     | 利用我的同组群体评分和行为给出推荐                       | 用户评分+社区评分          |
| 基于内容 | 基于我过去的评分和行为根据我所喜欢的内容（属性）做出推荐 | 用户评分+物品属性          |
| 基于知识 | 基于我对某些内容(属性)的精确要求给出推荐                 | 用户要求+物品属性+领域知识 |

1. 基于约束的推荐系统
2. 基于案例的推荐系统

如何实现基于知识的推荐系统的互动性？

1. 会话式系统
2. 基于搜索的系统
3. 基于导航的推荐



# 2 基于近邻的协同过滤

评分矩阵类型：连续评分，间隔评分，顺序评分，二元评分，一元评分。

**长尾分布**。

## 基于用户的近邻模型

利用每位用户$u$的评分计算每位用户的平均评分$\mu_u$

$$\mu_u = \frac{\sum_{k\in I_u} r_{uk}}{|I_u|}$$

使用Pearson相关系数定义相似度

$Sim(u,v) = Pearson(u,v) = \frac{\sum_{k\in I_u \cap I_v} (r_{uk}- \mu_{u}) \cdot (r_{vk}-\mu_{v}) }{\sqrt{\sum_{k \in I_u \cap i_v} (r_{uk}- \mu_{u})^2} \cdot \sqrt{\sum_{k \in I_u \cap i_v} (r_{vk}- \mu_{v})^2} }$

但不同的用户其评分尺度不同。所以进行均值中心化：

$s_{uj} = r_{rj} - \mu_u \forall u \in \{1...m\}$

整体的预测：

$\hat{r}_{u,j} = \mu_u + \frac{\sum_{v\in P_u(j)} Sim(u,v) \cdot s_{vj}}{|\sum_{v\in P_u(j)} Sim(u,v) |} = \mu_u + \frac{\sum_{v\in P_u(j)} Sim(u,v) \cdot (r_{vj}-\mu_{v})}{|\sum_{v\in P_u(j)} Sim(u,v) |}$

**普通理解**：

对目标用户与候选用户两两计算Pearson相似度，再对每用户的评分进行均值化处理，目标用户u对物品j的预测值等于用户u的评分均值加上前k个Pearson用户的Pearson值(权重)乘以均值化后的用户对物品j的评分。



相似度函数变形：RawCosine，DiscountedSim等。

降低长尾效应对Pearson影响，添加物品j权重$w_j$（idf概念）:

$w_j = \log(\frac{m}{m_j}) \forall j \in \{1...n\}$

$ Pearson(u,v) = \frac{\sum_{k\in I_u \cap I_v} w_k \cdot (r_{uk}- \mu_{u}) \cdot (r_{vk}-\mu_{v}) }{\sqrt{\sum_{k \in I_u \cap i_v} (r_{uk}- \mu_{u})^2} \cdot \sqrt{\sum_{k \in I_u \cap i_v} (r_{vk}- \mu_{v})^2} }$



## 基于物品的近邻模型

物品i与j的相似度计算：

$AdjustedConsine(i,j) = \frac{\sum_{u\in U_i \cap U_j} s_{u_i} \cdot s_{u_j}}{\sqrt{\sum_{u\in U_i \cap U_j} s_{ui}^2 } \cdot \sqrt{\sum_{u\in U_i \cap U_j} s_{uj}^2 }}$

用户u对物品t的预测评分：

$\hat{r}_{ut} =  \frac{\sum_{j \in Q_t(u)} AdjustedCosine(j,t) r_{uj}}{\sum_{j \in Q_t(u)}|AdjustedCosine(j,t)|}$





基于近邻的方法优势是简单和直观，但里现阶段在大规模数据上变得无法实现，基于用户的方法，其离线阶段要求至少$O(m^2)$， 可扩展性不够实用。

## 降维与近邻方法

使用PCA或SVD对评价矩阵降维。如对用户的协同过滤降维，将mxn的矩阵降维成mxd，d远小于n。

## 近邻方法的回归模型视角

基于用户的模型将预测评分表达为同一列ovs的评分的线性组合。而基于物品的模型表达为同一行中评分的线性组合。基于近邻的模型是线性回归模型的启发式变形，其中系统被启发式的设定为相关物品/用户的相似性，不相关则系数为0。**论文引用**

**基于用户的最近邻回归**

$\text{Minimize}\ J_u = \sum_{j\in I_u}(r_{uj} - \hat{r}_{uj})^2$

同时添加了用户偏置项，物品偏置项，调节因子，正则化。

基于物品的与之类似



## 基于紧邻方法的图模型

**用户-物品图**

不使用Pearson相关系数，而是使用结构化测度定义近邻，其是无向二分图。

这样可以使用**随机游走**定义近邻，更进一步的可以使用**Katz**(加权走)定义近邻

**物品-物品图**

用评分矩阵中的并集数量作为边的值，然后对结点的出度进行归一化。



# 3 基于模型的协同过滤

传统的分类或回归问题恰好是矩阵补全(或协同过滤)的特例。通常最精确的协同过滤方法都是基于模型的，尤其是潜在因子模型。潜在因子模型，对于解决协同过滤问题非常有效，但并不认为是解决数据分类的问题有效模型。

**决策和回归树**

对数据降维，然后对n个物品创建n个决策树。预测用户i对物品j的评分，mxd的矩阵第i行被用作测试数据，第j个决策'/回归树作为模型。

**基于规则的协同过滤**

面向物品的模型与面向用户的模型。关联规则的方法在基于Web的个性化推荐系统中得到了广泛应用，还是可使用序列模式挖掘模型，进一步扩展到包含时间信息的数据上。

**朴素贝叶斯协同过滤**

例子很简单，可见书籍64页。

## 潜在因子模型

潜在因子模型在推荐系统中被认为是一种最先进的方法。矩阵银子分解给出了一种优雅的同时利用行列相关性来估计整个数据矩阵的方法。其复杂度时期称为协同过滤中最先进的方法。

几何解释：

思想：在于找到一个隐向量集合，使得基于这些隐向量定义的从超平面到数据点(表示用户的单个评分值)的均方距离尽可能地小。因此，我们必须使用部分确定的数据集去恢复数据近似存在的低维度超平面。不过，如果数据没有任何关联性和冗余，那潜在因子模型是无法工作的。

低秩解释：

 其作用是因为因子分解(factorization)作用。评分矩阵可以表示为：

$R\approx UV^T$

U是空间的基，V是列空间的基。U的行记为用户因子，其包含与用户i对评分矩阵中的k各概念的亲和度相对应的k个值。每一列称为隐向量。

各矩阵分解方法之间的关键差异出现在对U和V的约束如潜在向量的正交性或非负性和目标函数性质。

**无约束矩阵分解**

对因子矩阵UV我有约束，许多文献将无约束矩阵分解当作奇异值分解SVD，严格说 是错误的。在SVD中，UV的列表示都是正交的。

UV的优化方式：梯度下降和交替最小二乘

交替最小二乘：

1. 固定U不变，将问题转化为n个最小二乘问题，每个物品是独立的，所以可以并行化。
2. 固定V不变，同样转化成m个最小二乘问题，
3. 两步迭代，直到收敛。

加权版本的ALS特别适合隐式反馈。但它效率不如大规模已知评分情况下的随机梯度下降。

改进：添加用户和物品偏差，减少过拟合。

![1561366302556](C:\Users\chenshuai\AppData\Roaming\Typora\typora-user-images\1561366302556.png)



引入隐式的反馈

非对称因子模型，$R\approx [FY]V^T$, 这种方法更有效，基本思想是：如果两个用户已经评价了e类似的物品，就会有类似的用户因子，而无需考虑具体的评分值。并且其参数量更小于U的mxk 因为n<<m。另一个有点是不需要用户参数化。

## 奇异值分解

如果矩阵R完全已知且未使用正则化，在SVD和非约束矩阵分解情况下，J的最优值是相同的。目标函数$J=\frac{1}{2}||R-UV^T||^2$

R不完全已知情况下，首先对矩阵进行均值化处理并用0填充?（即对预测值使用均值进行填充），然后使用SVD对这些位置进行更新，直到收敛。这方法不能保证收敛到全局最优，当大部分值未知时更明显，初始偏差对结果影响更大。

## 非负矩阵分解

NMF的优点在于可解释性。

**隐式反馈中的数值表示为置信度，而显示反馈中的数值表示偏好。**



## 总结

协同过滤于分类问题密切相关。

机器学习与推荐算法密切相关：关联规则，朴素贝叶斯，SVM，决策/回归树。甚至神经网络如RBM都应用

潜在因子方法是协同过滤最先进的方法。基本目标函数和约束的变体被应用于不同形式的矩阵分解。

关于如何选择底层优化问题的解决方法工作已经开展很多。



## 4 基于内容的推荐系统

基于内容的推荐系统尝试为用户匹配那些与其喜欢的物品相似的物品，这种相似度不一定基于用户之间的评分相关性，而是基于用户喜欢对象的属性。相比CF，更关注目标用户自己的评分，以及用户喜欢物品的属性。其它用户在基于内容的系统中角色不太重要，基于内容的方法利用不同的数据源来给出推荐。

依赖的两个数据来源： 

1. 根据以内容为中心的属性对各种物品的描述，如物品文本描述。
2. 用户画像。根据用户对各种物品的反馈而生成。有显式和隐式反馈。 前者对应评分，后者对应用户动作。

在基于内容的推荐算法中，其它用户的评分同上没有任何作用。，如冷启动问题，只要有足够的用户自己兴趣信息可用，就可以使用基于内容的推荐方法。减轻了冷启动问题。缺点可能是对用户的推荐缺乏多样性。基于内容的推荐可以使用结构或非结构化属性信息。

基于内容的系统的主要组件：(离线)预处理，(离线)学习部分，在线预测部分。

1. 预处理和特征提取：
2. 基于内容的用户画像学习：
3. 过滤和推荐

自动学习各特征的重要性称为**特征加权**。

收集用户的偏好，用户对物品的喜欢或不喜欢最终被转换为一元，二元，基于区间的或实数评分。获取评分的过程也可以被看作是提取要用户学习的类标签或因变量的过程。

提取关键词的数量应控制在50-300之间。

基尼指数更容易理解，熵度量具有更坚实的信息论的数学基础。

CHI2统计量可以通过将单词和类的共同出现处理为列联表来计算。其可以度量列链表中不同歌唱的观测值和期望值之间的归一化偏差。值越大表示特定此和物品有更高的相关程度，可以取CHI2前K个特征。



基于内容的优点：

1. 基于内容的系统仅对新用户具有冷启动问题，而协同系统对新用户和新物品都有冷启动问题。
2. 在物品的特征上有一定的解释性，但协同通常没有办法给出这样的解释
3. 基于内容的方法可以与县城的文本分类一起使用。

缺点：

1. 基于内容的系统倾向于找到与用户迄今为止所看的类似物品，称为 **过度特化**，即缺乏新颖性 多样性。
2. 无法解决新用户的冷启动问题。



# 5 基于知识的推荐系统

基于知识的推荐系统的适应情况：

1. 用户想要明确描述其需求，因此系统中必须有交互组件。协同过滤和基于内容的系统都不允许这种类型的用户反馈。
2. 由于物品的类型和选项导致的物品域的复杂性，某些特定类型的物品评分可能很呐获得。
3. 评分对时间敏感。



| 模型     | 关注点        | 物品属性 | 交互性 | 概念目标                                                 | 输入                           |
| -------- | ------------- | -------- | ------ | -------------------------------------------------------- | ------------------------------ |
| 协同过滤 | 其它用户/物品 | 不关心   | 无     | 基于协同的方法利用用户本人或同伴的评分和活动给出推荐结果 | 用户评分+社区评分              |
| 基于内容 | 自身          | 关心     | 无     | 基于用户过去对内容(属性)的评分和活动，给出推荐结果       | 用户评分+物品属性              |
| 基于知识 | 自身          | 关心     | 有     | 基于用户明确的内容(属性)需求说明，给出推荐结果           | 用户需求说明+物品属性+领域知识 |



根据用户的交互方法和辅助用户交互的相关知识库，基于知识的推荐系统可以分成：

1. 基于约束的推荐系统，以物品的属性为起点
2. 基于案例的推荐系统，以实例为起点

交互的三种实现：会话系统，搜索系统，导航系统



相似性度量，传统的是按照重要程度排序。

考虑d个属性来描述产品的应用，我们想确定在d个属性的邻域的子集S上定义的两个部分属性向量之间的相似度值。X为已知，T表示目标。相似度计算：

$f(\bar{T},\bar{X}) = \frac{\sum_{i \in S} w_i \cdot \text{Sim}(t_i, x_i)}{\sum_{i \in S} w_i}$

而X,Y的第i个属性相似度计算：

$\text{Sim}(t_i, x_i) = 1 - \frac{|t_i - x_i|}{\text{max}_i - \text{min}_i}$

在对称度量情况下，相似度完全由两个属性之间的差异定义，但在非对称属性情况下，可以额外添加一个非对称奖励。这取决于目标属性值更大还是更小。当目标值更大时候好，计算如下：

$\text{Sim}(t_i, x_i) = 1 - \frac{|t_i-x_i|}{\max_i - \min_i} + \underbrace{\alpha_i \cdot I(x_i>t_i) \cdot \frac{|t_i-x_i|}{\max_i -\min_i}}_{\text{非对称奖励}}$

$\alpha_i \ge 0$是用户定义的参数，$I(x_i>t_i)$是指示函数，如果$x_i > t_i$，则取值为1，否则为0。这样，当属性值大于目标值时候，奖励才生效。



**在相似度计算中合并多样性**

一种方法是在排名$b \cdot k$中，选择$k$个进行推荐，效果并不好。称为 有界随机选择策略。

另一种是有界贪婪选择策略。先选取排名$b \cdot k$，然后递增地从这协众创建一个多样的包含k中实例的集合。



基于知识的推荐系统往往是为了给更昂贵和偶尔购买的物品设计的，其是高度量身定制的。



# 6 基于集成的呼和推荐模型

协同过滤：使用一个社区(commuity)中所有用户的评分来做推荐。

基于内容：使用单一用户评分和以属性为中心的物品描述来做推荐。

基于知识：需要根据用户明确的需求来做推荐，而不需要任何历史评分。

